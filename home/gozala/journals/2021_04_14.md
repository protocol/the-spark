---
title: Apr 14th, 2021
---

## [[ChainNFT]] Design
### Uses [wighawag/eip721-subgraph](https://thegraph.com/explorer/subgraph/wighawag/eip721-subgraph) to query  [[Ethereum]] chain and collect [[EIP-721]] tokens.
Here is an example query:

```graphql
{
  meta: _meta {
    block {
      hash
      number
    }
  }
  stat:all(id: "all") {
    numTokenContracts
    numTokens
    numOwners
  }
  tokens(first: 10 where: { tokenURI_not: "" id_gt: $lastID }) {
    id,
    tokenID
    tokenURI
    mintTime
    contract {
      id
      name
      symbol
    }
  }
}
```

#### It provides `stats` about known tokens `{ numTokens, numOwners, numTokensContracts}` and 100 `tokens` from the `$lastID`.
#### Unfortunately we can use sorting here because we will not be able to paginate, according to docs
####
:PROPERTIES:
:url: https://thegraph.com/docs/graphql-api#pagination
:END:
> It is worth noting that the default sort order is by ID in ascending alphanumeric order, not by creation time.
#### 
> If a client needs to retrieve a large number of entities, it is much more performant to base queries on an attribute and filter by that attribute.

In practice pagination with `skip` is capped at `5000`
#### `id` seems to be`${contract.id}_${tokenID}` and I'm not sure if paginating via `id` might cause use to miss some tokens.
##### Do contract and token IDs always increment ? If so it does not seem like a problem.
##### We could fork the graph index in order to include block number into responses and paginate that way.
###### In fact we could do following:
###### 1. Scheduled [[chain scanner]] actor manages chain scan state:
```ts
interface Chain {
  /**
   * Last known block in chain.
   */
  block: number
}
```
It queries the graph and updates `chain.block` when new blocks are discovered.
###### 2. Scheduled [[token scanner]] actor manages token scan via cursor:
```ts
interface Cursor {
  /**
   * Last block been scan
   */
  block: number
  /**
   * Last recorder token id.
   */
  token: string
}
```
It queries the graph to get next 100 tokens with in the `cursor.block`. If `< 100` tokens were found and `cursor.block < chain.block`, it updates cursor to continue scan from the next block. Otherwise it updates `cursor.token` to the last `token.id`.

```ts
if (tokens.length < 100 && cursor.block < chain.block) {
  cursor = { block: cursor.block + 1,  token: '' }
} else {
  cursor = { ...cursor, token: last(tokens).id }
}
```

It also stores info from discovered tokens

|id|tokenID|tokenURL|blockNumber|mintTime|contractID|name|symbol|
|--|--------|----------|-------------|----------|-----------|-----|--------|
|0x..._10...23|10...23|https://api../opensea/..23|69..61|15..49|0xff...1e49|CryptoBeasties|CRYB|
######
###### 3. Scheduled [[token analyzer]] actor goes over recorded tokens and and attempts to fetch metadata from `tokenURL`. If it is a JSON, URLs to linked resources are stored

|tokenURI|metadata|assetURL|
|---------|---------|----------|

Analyzer also maintains a table containing entries for all tokenURIs for which attempt of fetch was made.

|tokenURI|status|attempt|
|---------|-------|--------|

Where status is:

```ts
type Status =
  | { type: 'queued' } // no attempts were made
  | { type: 'pending' } // attempt is been made
  | { type: 'fetch-failed', statusCode: number }
  | { type: 'parse-failed', reason: string }
```
#### The [[Orch]] actor should be able to go over asset table and fetch & pin, maintaining own state of what it was able to complete or fail.
####
